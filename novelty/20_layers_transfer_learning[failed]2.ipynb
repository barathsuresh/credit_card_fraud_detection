{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle, resample\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "import joblib\n",
    "from sklearn.svm import SVC\n",
    "import pickle\n",
    "class_label = ['Non-Default(0)','Default(1)'] # env var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# readinf the dataset\n",
    "data = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Class', ylabel='count'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# seperating features and class\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "sns.countplot(x='Class',data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\barath_suresh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\barath_suresh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to C:\\Users\\barath_suresh/.cache\\torch\\hub\\checkpoints\\vgg16-397923af.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "# Load a pre-trained CNN model\n",
    "model = models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the last layer\n",
    "model.classifier = nn.Sequential(*list(model.classifier.children())[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the pre-trained layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train an SVM model using the output of the last layer of the CNN as input\n",
    "train_features = []\n",
    "test_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [64, 3, 3, 3], expected input[1, 1, 1, 30] to have 3 channels, but got 1 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(X_train)):\n\u001b[0;32m      4\u001b[0m     inputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(X_train[i])\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m     outputs \u001b[39m=\u001b[39m model(inputs)\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m      6\u001b[0m     inputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((inputs, inputs, inputs), dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m      7\u001b[0m     train_features\u001b[39m.\u001b[39mappend(outputs[\u001b[39m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\barath_suresh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\barath_suresh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\vgg.py:66\u001b[0m, in \u001b[0;36mVGG.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m---> 66\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeatures(x)\n\u001b[0;32m     67\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavgpool(x)\n\u001b[0;32m     68\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mflatten(x, \u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\barath_suresh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\barath_suresh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\barath_suresh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\barath_suresh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\Users\\barath_suresh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 3, 3, 3], expected input[1, 1, 1, 30] to have 3 channels, but got 1 channels instead"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    inputs = torch.from_numpy(X_train[i]).float().unsqueeze(0).unsqueeze(0)\n",
    "    outputs = model(inputs).detach().numpy()\n",
    "    inputs = torch.cat((inputs, inputs, inputs), dim=1)\n",
    "    train_features.append(outputs[0])\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    inputs = torch.from_numpy(X_test[i]).float().unsqueeze(0).unsqueeze(0)\n",
    "    outputs = model(inputs).detach().numpy()\n",
    "    inputs = torch.cat((inputs, inputs, inputs), dim=1)\n",
    "    test_features.append(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC()\n",
    "svm.fit(train_features, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = svm.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the accuracy of the model\n",
    "accuracy = accuracy_score(Y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
