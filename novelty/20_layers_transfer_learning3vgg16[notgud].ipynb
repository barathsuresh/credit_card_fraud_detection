{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from keras.models import Model\n",
    "from keras.applications import VGG16, ResNet50\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle, resample\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "import tensorflow.keras as keras\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "import joblib\n",
    "from sklearn.svm import SVC\n",
    "from skimage import color, io, transform\n",
    "import pickle\n",
    "class_label = ['Non-Default(0)','Default(1)'] # env var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['NPY_NUMPY_ALLOWED_HOST_MACHINESIZE'] = str(2 * 1024**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    492\n",
      "1    492\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('D:\\Barath Suresh Docs\\PROGRAMMING\\MACHINE LEARNING\\credit_card_fraud_detection\\creditcard.csv')\n",
    "# Separate the fraud and non-fraud examples\n",
    "fraud = df[df['Class'] == 1]\n",
    "non_fraud = df[df['Class'] == 0]\n",
    "# Random under-sampling of the majority class\n",
    "non_fraud_downsampled = resample(non_fraud, replace=False, n_samples=len(fraud), random_state=42)\n",
    "# Combine minority class with downsampled majority class\n",
    "balanced_df = pd.concat([fraud, non_fraud_downsampled])\n",
    "# Shuffle the examples\n",
    "balanced_df = shuffle(balanced_df, random_state=42)\n",
    "# Print the class distribution of the balanced dataset\n",
    "print(balanced_df['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "X = balanced_df.drop('Class', axis=1).values\n",
    "y = balanced_df['Class'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(984, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# Normalize the values in the matrix\n",
    "imgX = (X - np.min(X)) / (np.max(X) - np.min(X))\n",
    "# Reshape the matrix into a 3D array of grayscale images\n",
    "imgX = np.reshape(imgX, (imgX.shape[0], imgX.shape[1], 1))\n",
    "imgX = np.repeat(imgX, 3, axis=2)  # Convert grayscale to RGB\n",
    "# Optionally, resize the images to a specific size\n",
    "imgX = np.array([transform.resize(x, (224, 224, 3)) for x in X])\n",
    "print(imgX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the images for use with VGG16\n",
    "imgX = preprocess_input(imgX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained VGG16 model\n",
    "base_model =  ResNet50(weights='imagenet',include_top=False,input_shape=(224,224,3))\n",
    "# Remove the last layer of the VGG16 model\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an SVM with an RBF kernel as the output layer\n",
    "x = Dense(1, activation='sigmoid', name='svm')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model with the modified architecture\n",
    "model = keras.models.Model(inputs=base_model.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the weights of the pre-trained VGG16 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with binary crossentropy loss and an Adam optimizer\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(imgX, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "23/23 [==============================] - 53s 2s/step - loss: 30.3853 - accuracy: 0.5056 - val_loss: 28.8535 - val_accuracy: 0.4684\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 47s 2s/step - loss: 10.0231 - accuracy: 0.5240 - val_loss: 7.0019 - val_accuracy: 0.5316\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 46s 2s/step - loss: 8.9847 - accuracy: 0.5085 - val_loss: 0.8036 - val_accuracy: 0.5696\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 46s 2s/step - loss: 4.4160 - accuracy: 0.4929 - val_loss: 2.7334 - val_accuracy: 0.4684\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 46s 2s/step - loss: 6.8639 - accuracy: 0.5085 - val_loss: 3.3491 - val_accuracy: 0.5316\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 44s 2s/step - loss: 2.8595 - accuracy: 0.5325 - val_loss: 0.6857 - val_accuracy: 0.6076\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 45s 2s/step - loss: 6.0068 - accuracy: 0.5155 - val_loss: 2.0754 - val_accuracy: 0.5823\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 46s 2s/step - loss: 4.6428 - accuracy: 0.5141 - val_loss: 1.0242 - val_accuracy: 0.4684\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 44s 2s/step - loss: 3.5899 - accuracy: 0.4873 - val_loss: 6.9126 - val_accuracy: 0.5316\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 44s 2s/step - loss: 14.4265 - accuracy: 0.5085 - val_loss: 16.0081 - val_accuracy: 0.5316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28c0dbc6d90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model on the training set\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 12s 2s/step - loss: 23.7075 - accuracy: 0.4365\n",
      "Accuracy: 0.43654823303222656\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the testing set\n",
    "accuracy = model.evaluate(X_test, y_test)[1]\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add an SVM kernel layer\n",
    "# svm = SVC(kernel='rbf')\n",
    "# x = svm.fit(x, y_train).support_vectors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the new model\n",
    "# model = Model(inputs=base_model.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Freeze the pre-trained layers\n",
    "# for layer in base_model.layers:\n",
    "#     layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compile the model\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train the model\n",
    "# model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate the model\n",
    "# y_pred = model.predict(X_test)\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
