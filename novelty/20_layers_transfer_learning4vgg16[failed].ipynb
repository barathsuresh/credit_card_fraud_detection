{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from keras.models import Model\n",
    "from keras.applications import VGG16, ResNet50\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle, resample\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "import tensorflow.keras as keras\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "import joblib\n",
    "from sklearn.svm import SVC\n",
    "from skimage import color, io, transform\n",
    "import pickle\n",
    "class_label = ['Non-Default(0)','Default(1)'] # env var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    492\n",
      "1    492\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('D:\\Barath Suresh Docs\\PROGRAMMING\\MACHINE LEARNING\\credit_card_fraud_detection\\creditcard.csv')\n",
    "# Separate the fraud and non-fraud examples\n",
    "fraud = df[df['Class'] == 1]\n",
    "non_fraud = df[df['Class'] == 0]\n",
    "# Random under-sampling of the majority class\n",
    "non_fraud_downsampled = resample(non_fraud, replace=False, n_samples=len(fraud), random_state=42)\n",
    "# Combine minority class with downsampled majority class\n",
    "balanced_df = pd.concat([fraud, non_fraud_downsampled])\n",
    "# Shuffle the examples\n",
    "balanced_df = shuffle(balanced_df, random_state=42)\n",
    "# Print the class distribution of the balanced dataset\n",
    "print(balanced_df['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "X = balanced_df.drop('Class', axis=1).values\n",
    "y = balanced_df['Class'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC(kernel='linear')\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightsvm = np.append(svm.coef_[0][:24], svm.intercept_)\n",
    "weightsvm = weightsvm.reshape(1, 25)\n",
    "reshaped_weight_svm = svm.coef_[0][:25].reshape(25,1)\n",
    "#bias = svm.intercept_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(984, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# Normalize the values in the matrix\n",
    "imgX = (X - np.min(X)) / (np.max(X) - np.min(X))\n",
    "# Reshape the matrix into a 3D array of grayscale images\n",
    "imgX = np.reshape(imgX, (imgX.shape[0], imgX.shape[1], 1))\n",
    "imgX = np.repeat(imgX, 3, axis=2)  # Convert grayscale to RGB\n",
    "# Optionally, resize the images to a specific size\n",
    "imgX = np.array([transform.resize(x, (224, 224, 3)) for x in X])\n",
    "print(imgX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the images for use with VGG16\n",
    "imgX = preprocess_input(imgX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 7, 7, 512)\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained VGG16 model\n",
    "base_model =  VGG16(weights='imagenet',include_top=False,input_shape=(224,224,3))\n",
    "# Remove the last layer of the VGG16 model\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "print(base_model.output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer dense_1 weight shape (512, 1) is not compatible with provided weight shape (25, 1).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Add an SVM with an RBF kernel as the output layer\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m x \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mDense(\u001b[39m1\u001b[39;49m, activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msoftmax\u001b[39;49m\u001b[39m'\u001b[39;49m, weights\u001b[39m=\u001b[39;49m[reshaped_weight_svm,svm\u001b[39m.\u001b[39;49mintercept_])(x)\n",
      "File \u001b[1;32mc:\\Users\\barath_suresh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\barath_suresh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\base_layer.py:1827\u001b[0m, in \u001b[0;36mLayer.set_weights\u001b[1;34m(self, weights)\u001b[0m\n\u001b[0;32m   1825\u001b[0m ref_shape \u001b[39m=\u001b[39m param\u001b[39m.\u001b[39mshape\n\u001b[0;32m   1826\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ref_shape\u001b[39m.\u001b[39mis_compatible_with(weight_shape):\n\u001b[1;32m-> 1827\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1828\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLayer \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m weight shape \u001b[39m\u001b[39m{\u001b[39;00mref_shape\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1829\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mis not compatible with provided weight \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1830\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mshape \u001b[39m\u001b[39m{\u001b[39;00mweight_shape\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1831\u001b[0m     )\n\u001b[0;32m   1832\u001b[0m weight_value_tuples\u001b[39m.\u001b[39mappend((param, weight))\n\u001b[0;32m   1833\u001b[0m weight_index \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: Layer dense_1 weight shape (512, 1) is not compatible with provided weight shape (25, 1)."
     ]
    }
   ],
   "source": [
    "# Add an SVM with an RBF kernel as the output layer\n",
    "x = keras.layers.Dense(1, activation='softmax', weights=[reshaped_weight_svm,svm.intercept_])(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model with the modified architecture\n",
    "model = keras.models.Model(inputs=base_model.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the weights of the pre-trained VGG16 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with binary crossentropy loss and an Adam optimizer\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(imgX, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "23/23 [==============================] - 56s 2s/step - loss: 20.6237 - accuracy: 0.5028 - val_loss: 0.9996 - val_accuracy: 0.4684\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 40s 2s/step - loss: 6.1753 - accuracy: 0.5339 - val_loss: 4.4806 - val_accuracy: 0.4684\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 40s 2s/step - loss: 4.1161 - accuracy: 0.5395 - val_loss: 5.4633 - val_accuracy: 0.5316\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 41s 2s/step - loss: 9.8989 - accuracy: 0.5424 - val_loss: 6.3930 - val_accuracy: 0.4684\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 41s 2s/step - loss: 4.4236 - accuracy: 0.5014 - val_loss: 1.0292 - val_accuracy: 0.5949\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 41s 2s/step - loss: 4.4097 - accuracy: 0.5155 - val_loss: 6.1336 - val_accuracy: 0.5316\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 42s 2s/step - loss: 6.4816 - accuracy: 0.4986 - val_loss: 1.1705 - val_accuracy: 0.5949\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 42s 2s/step - loss: 11.1235 - accuracy: 0.5268 - val_loss: 8.5863 - val_accuracy: 0.5316\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 41s 2s/step - loss: 10.6453 - accuracy: 0.4944 - val_loss: 5.7212 - val_accuracy: 0.4684\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 41s 2s/step - loss: 4.5686 - accuracy: 0.5056 - val_loss: 10.4913 - val_accuracy: 0.5316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15982756310>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model on the training set\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 10s 1s/step - loss: 15.6601 - accuracy: 0.4365\n",
      "Accuracy: 0.43654823303222656\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the testing set\n",
    "accuracy = model.evaluate(X_test, y_test)[1]\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add an SVM kernel layer\n",
    "# svm = SVC(kernel='rbf')\n",
    "# x = svm.fit(x, y_train).support_vectors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the new model\n",
    "# model = Model(inputs=base_model.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Freeze the pre-trained layers\n",
    "# for layer in base_model.layers:\n",
    "#     layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compile the model\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train the model\n",
    "# model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate the model\n",
    "# y_pred = model.predict(X_test)\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
